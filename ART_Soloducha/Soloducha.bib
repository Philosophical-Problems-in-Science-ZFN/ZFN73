
@article{wysocki_problem_2021,
	title = {The problem of indifference and homogeneity in {Austrian} economics: {Nozick}’s challenge revisited},
	issn = {0867-8286},
	shorttitle = {The problem of indifference and homogeneity in {Austrian} economics},
	url = {https://zfn.edu.pl/index.php/zfn/article/view/554},
	abstract = {The pivotal point in the Austrian literature on homogeneity, choice and indifference was constituted by Nozick’s On Austrian Methodology. Nozick provoked a long debate on the above notions within Austrianism. The aim of this paper is to elaborate such an account of homogeneity that would take the sting out of Nozick’s challenge and allow for non-trivial formulation of the law of diminishing marginal utility. Hence, we shall first take a closer look at the debate on indifference within the Austrian camp, while defending and building upon the Hoppean account vis-à-vis Block’s criticism. Our justification of the Hoppean position shall consist in showing that his account of the correct description of an action is not an ad hoc move aimed at solving just one problem of indifference but is highly intuitive and widely applicable. We conclude by restating the above-mentioned law, thus demonstrating that the Nozickian objection can be successfully replied.},
	language = {en-US},
	number = {71},
	urldate = {2022-01-24},
	journal = {Philosophical Problems in Science (Zagadnienia Filozoficzne w Nauce)},
	author = {Wysocki, Igor},
	month = dec,
	year = {2021},
	note = {Section: Articles},
	pages = {9--44},
	file = {Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/Y5J2XXCX/2022 - The problem of indifference and homogeneity in Aus.pdf:application/pdf;The problem of indifference and homogeneity in Austrian economics\: Nozick’s challenge revisited | Philosophical Problems in Science (Zagadnienia Filozoficzne w Nauce):/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/TWHWQWY3/554.html:text/html},
}

@book{dodig-crnkovic_representation_2017,
	address = {Cham},
	series = {Studies in {Applied} {Philosophy}, {Epistemology} and {Rational} {Ethics}, 28},
	title = {Representation and {Reality} in {Humans}, {Other} {Living} {Organisms} and {Intelligent} {Machines}},
	isbn = {3-319-43784-4},
	language = {en},
	publisher = {Springer International Publishing},
	author = {Dodig-Crnkovic, Gordana and Giovagnoli, Raffaela},
	editor = {Dodig-Crnkovic, Gordana. and Giovagnoli, Raffaela.},
	year = {2017},
	doi = {10.1007/978-3-319-43784-2},
}

@article{arrow_ordinalist-utilitarian_1973,
	title = {Some {Ordinalist}-{Utilitarian} {Notes} on {Rawls}'s {Theory} of {Justice}},
	volume = {70},
	issn = {0022-362X},
	shorttitle = {Some {Ordinalist}-{Utilitarian} {Notes}},
	url = {https://www.jstor.org/stable/2025006},
	doi = {10.2307/2025006},
	number = {9},
	urldate = {2023-01-11},
	journal = {The Journal of Philosophy},
	author = {Arrow, Kenneth J.},
	collaborator = {Rawls, John},
	month = may,
	year = {1973},
	note = {Publisher: Journal of Philosophy, Inc.},
	pages = {245--263},
	file = {JSTOR Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/9QNL4WXG/Arrow - 1973 - Review of Some Ordinalist-Utilitarian Notes on Raw.pdf:application/pdf},
}

@incollection{asimov_runaround_2004,
	address = {New York},
	edition = {Bantam hardcover edition},
	series = {Bantam spectra book},
	title = {Runaround},
	isbn = {978-0-553-80370-9},
	abstract = {The three laws of Robotics: 1) A robot may not injure a human being or, through inaction, allow a human being to come to harm 2) A robot must obey orders given to it by human beings except where such orders would conflict with the First Law. 3) A robot must protect its own existence as long as such protection does not conflict with the First or Second Law. With these three, simple directives, Isaac Asimov changed our perception of robots forever when he formulated the laws governing their behavior. In I, Robot, Asimov chronicles the development of the robot through a series of interlinked stories: from its primitive origins in the present to its ultimate perfection in the not-so-distant future--a future in which humanity itself may be rendered obsolete. Here are stories of robots gone mad, of mind-reading robots, and robots with a sense of humor. Of robot politicians, and robots who secretly run the world--all told with the dramatic blend of science fact and science fiction that has become Asmiov's trademark},
	language = {en},
	booktitle = {I, robot},
	publisher = {Bantam Books},
	author = {Asimov, Isaac},
	year = {2004},
	note = {OCLC: 53839993},
	keywords = {artificial intelligence, Artificial intelligence, Artificial Intelligence, Robots, Fiction, Science fiction, Intelligence artificielle, Nouvelles, Nouvelles américaines, Robots Fiction, Science fiction, American, short stories, Short stories, Short stories, American},
	pages = {30--55},
}

@article{awad_universals_2020,
	title = {Universals and variations in moral decisions made in 42 countries by 70,000 participants},
	volume = {117},
	url = {https://www.pnas.org/doi/10.1073/pnas.1911517117},
	doi = {10.1073/pnas.1911517117},
	abstract = {When do people find it acceptable to sacrifice one life to save many? Cross-cultural studies suggested a complex pattern of universals and variations in the way people approach this question, but data were often based on small samples from a small number of countries outside of the Western world. Here we analyze responses to three sacrificial dilemmas by 70,000 participants in 10 languages and 42 countries. In every country, the three dilemmas displayed the same qualitative ordering of sacrifice acceptability, suggesting that this ordering is best explained by basic cognitive processes rather than cultural norms. The quantitative acceptability of each sacrifice, however, showed substantial country-level variations. We show that low relational mobility (where people are more cautious about not alienating their current social partners) is strongly associated with the rejection of sacrifices for the greater good (especially for Eastern countries), which may be explained by the signaling value of this rejection. We make our dataset fully available as a public resource for researchers studying universals and variations in human morality.},
	number = {5},
	urldate = {2023-01-11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Awad, Edmond and Dsouza, Sohan and Shariff, Azim and Rahwan, Iyad and Bonnefon, Jean-François},
	month = feb,
	year = {2020},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {2332--2337},
	file = {Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/KCUSUP8V/Awad et al. - 2020 - Universals and variations in moral decisions made .pdf:application/pdf},
}

@article{awad_moral_2018,
	title = {The {Moral} {Machine} experiment},
	volume = {563},
	copyright = {2018 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-018-0637-6},
	doi = {10.1038/s41586-018-0637-6},
	abstract = {With the rapid development of artificial intelligence have come concerns about how machines will make moral decisions, and the major challenge of quantifying societal expectations about the ethical principles that should guide machine behaviour. To address this challenge, we deployed the Moral Machine, an online experimental platform designed to explore the moral dilemmas faced by autonomous vehicles. This platform gathered 40 million decisions in ten languages from millions of people in 233 countries and territories. Here we describe the results of this experiment. First, we summarize global moral preferences. Second, we document individual variations in preferences, based on respondents’ demographics. Third, we report cross-cultural ethical variation, and uncover three major clusters of countries. Fourth, we show that these differences correlate with modern institutions and deep cultural traits. We discuss how these preferences can contribute to developing global, socially acceptable principles for machine ethics. All data used in this article are publicly available.},
	language = {en},
	number = {7729},
	urldate = {2023-01-11},
	journal = {Nature},
	author = {Awad, Edmond and Dsouza, Sohan and Kim, Richard and Schulz, Jonathan and Henrich, Joseph and Shariff, Azim and Bonnefon, Jean-François and Rahwan, Iyad},
	month = nov,
	year = {2018},
	note = {Number: 7729
Publisher: Nature Publishing Group},
	keywords = {Culture, Ethics, Human behaviour},
	pages = {59--64},
	file = {Pełny tekst:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/QIBZ74T9/Awad et al. - 2018 - The Moral Machine experiment.pdf:application/pdf},
}

@article{bigman_life_2020,
	title = {Life and death decisions of autonomous vehicles},
	volume = {579},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/s41586-020-1987-4},
	doi = {10.1038/s41586-020-1987-4},
	language = {en},
	number = {7797},
	urldate = {2023-01-11},
	journal = {Nature},
	author = {Bigman, Yochanan E. and Gray, Kurt},
	month = mar,
	year = {2020},
	pages = {E1--E2},
}

@book{bostrom_superintelligence_2016,
	address = {Oxford},
	title = {Superintelligence: {Paths}, {Dangers}, {Strategies}},
	isbn = {978-0-19-967811-2},
	shorttitle = {Superintelligence},
	language = {en},
	publisher = {Oxford University Press},
	author = {Bostrom, Nick},
	year = {2016},
	note = {OCLC: ocn881706835},
	keywords = {Philosophy, Artificial intelligence, Cognitive science},
}

@article{burrell_how_2016,
	title = {How the machine ‘thinks’: {Understanding} opacity in machine learning algorithms},
	volume = {3},
	issn = {2053-9517},
	shorttitle = {How the machine ‘thinks’},
	url = {https://doi.org/10.1177/2053951715622512},
	doi = {10.1177/2053951715622512},
	abstract = {This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm.},
	language = {en},
	number = {1},
	urldate = {2023-01-11},
	journal = {Big Data \& Society},
	author = {Burrell, Jenna},
	month = jun,
	year = {2016},
	note = {Publisher: SAGE Publications Ltd},
	pages = {1--12},
	file = {SAGE PDF Full Text:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/9QG3DXYW/Burrell - 2016 - How the machine ‘thinks’ Understanding opacity in.pdf:application/pdf},
}

@article{czyzowska_formy_1993,
	title = {Formy rozumowania moralnego {Polaków} w świetle danych z badania metodą {Lawrence}’a {Kohlberga}},
	volume = {2},
	number = {1},
	journal = {Kwartalnik Polskiej Psychologii Rozwojowej},
	author = {Czyżowska, Dorota and Niemczyński, Adam and Kmieć, Ewa},
	year = {1993},
	pages = {19--38},
}

@article{eschenbach_transparency_2021,
	title = {Transparency and the {Black} {Box} {Problem}: {Why} {We} {Do} {Not} {Trust} {AI}},
	volume = {34},
	issn = {2210-5441},
	shorttitle = {Transparency and the {Black} {Box} {Problem}},
	url = {https://doi.org/10.1007/s13347-021-00477-0},
	doi = {10.1007/s13347-021-00477-0},
	abstract = {With automation of routine decisions coupled with more intricate and complex information architecture operating this automation, concerns are increasing about the trustworthiness of these systems. These concerns are exacerbated by a class of artificial intelligence (AI) that uses deep learning (DL), an algorithmic system of deep neural networks, which on the whole remain opaque or hidden from human comprehension. This situation is commonly referred to as the black box problem in AI. Without understanding how AI reaches its conclusions, it is an open question to what extent we can trust these systems. The question of trust becomes more urgent as we delegate more and more decision-making to and increasingly rely on AI to safeguard significant human goods, such as security, healthcare, and safety. Models that “open the black box” by making the non-linear and complex decision process understandable by human observers are promising solutions to the black box problem in AI but are limited, at least in their current state, in their ability to make these processes less opaque to most observers. A philosophical analysis of trust will show why transparency is a necessary condition for trust and eventually for judging AI to be trustworthy. A more fruitful route for establishing trust in AI is to acknowledge that AI is situated within a socio-technical system that mediates trust, and by increasing the trustworthiness of these systems, we thereby increase trust in AI.},
	language = {en},
	number = {4},
	urldate = {2023-01-11},
	journal = {Philosophy \& Technology},
	author = {Eschenbach, Warren J. von},
	month = dec,
	year = {2021},
	keywords = {Artificial intelligence, Black box, Deep learning, Transparency, Trust, Trustworthiness},
	pages = {1607--1622},
	file = {Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/WAPVLHSZ/von Eschenbach - 2021 - Transparency and the Black Box Problem Why We Do .pdf:application/pdf},
}

@incollection{foot_problem_2002,
	address = {Oxford},
	title = {The {Problem} of {Abortion} and the {Doctrine} of the {Double} {Effect}},
	isbn = {978-0-19-925286-2},
	url = {https://doi.org/10.1093/0199252866.003.0002},
	abstract = {Abortion is considered in relation to the doctrine of the double effect, which distinguishes between the intentions behind an action and consequences foreseen but not desired. This doctrine, often used to defend the position of the Catholic Church on abortion, is here rejected. Alternative distinctions are drawn, between what we do and what we allow to happen, and between the infringement of ‘positive’ and ‘negative’ duties. These distinctions are applied to the problem of abortion and to other moral dilemmas.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Virtues and {Vices}: {And} {Other} {Essays} in {Moral} {Philosophy}},
	publisher = {Oxford University Press},
	author = {Foot, Philippa},
	editor = {Foot, Philippa},
	month = oct,
	year = {2002},
	doi = {10.1093/0199252866.003.0002},
	pages = {5--15},
	file = {Przesłana wersja:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/6F6HMDEX/Foot - 2002 - The Problem of Abortion and the Doctrine of the Do.pdf:application/pdf;Snapshot:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/FS37KXD8/162979508.html:text/html},
}

@book{fukuyama_trust_1995,
	address = {New York},
	edition = {1},
	series = {A {Free} {Press} paperbacks book},
	title = {Trust: {The} {Social} {Virtues} and the {Creation} of {Prosperity}},
	isbn = {978-0-684-82525-0 978-0-02-910976-2},
	shorttitle = {Trust},
	language = {en},
	publisher = {Free Press},
	author = {Fukuyama, Francis},
	year = {1995},
	annote = {Includes bibliographical references (p. 421-441) and index},
	annote = {The idea of trust: the improbable power of culture in the making of economic society -- Low-trust societies and the paradox of family values -- High-trust societies and the challenge of sustaining sociability -- American society and the crisis of trust -- Enriching trust: combining traditional culture and modern institutions in the twenty-first century},
}

@incollection{furnkranz_preference_2011,
	address = {Berlin, Heidelberg},
	title = {Preference {Learning}: {An} {Introduction}},
	isbn = {978-3-642-14125-6},
	shorttitle = {Preference {Learning}},
	url = {https://doi.org/10.1007/978-3-642-14125-6_1},
	abstract = {This introduction gives a brief overview of the field of preference learning and, along the way, tries to establish a unified terminology. Special emphasis will be put on learning to rank, which is by now one of the most extensively studied problem tasks in preference learning and also prominently represented in this book. We propose a categorization of ranking problems into object ranking, instance ranking, and label ranking. Moreover, we introduce these scenarios in a formal way, discuss different ways in which the learning of ranking functions can be approached, and explain how the contributions collected in this book relate to this categorization. Finally, we also highlight some important applications of preference learning methods.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Preference {Learning}},
	publisher = {Springer},
	author = {Fürnkranz, Johannes and Hüllermeier, Eyke},
	editor = {Fürnkranz, Johannes and Hüllermeier, Eyke},
	year = {2011},
	doi = {10.1007/978-3-642-14125-6_1},
	keywords = {Preference Learning, Ranking Function, Ranking Problem, Recommender System, Utility Function},
	pages = {1--17},
	file = {Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/KVAGJKB4/Fürnkranz i Hüllermeier - 2011 - Preference Learning An Introduction.pdf:application/pdf},
}

@book{gellner_words_2005,
	address = {London},
	edition = {1. publ},
	series = {Routledge classics},
	title = {Words and {Things}: {An} {Examination} of, and an {Attack} on, {Linguistic} {Philosophy}},
	isbn = {978-0-415-34548-4},
	shorttitle = {Words and {Things}},
	language = {en},
	publisher = {Routledge},
	author = {Gellner, Ernest},
	collaborator = {Russell, Bertrand and Jarvie, Ian C.},
	year = {2005},
	annote = {Includes index. - Originally published: London: Gollancz, 1959. - Formerly CIP},
}

@book{giddens_modernity_1991,
	address = {Stanford, CA},
	title = {Modernity and {Self}-{Identity}: {Self} and {Society} in the {Late} {Modern} {Age}},
	isbn = {978-0-8047-1944-5},
	shorttitle = {Modernity and {Self}-{Identity}},
	language = {en},
	publisher = {Stanford University Press},
	author = {Giddens, Anthony},
	year = {1991},
	keywords = {Psychological aspects, Civilization, Modern, Identity (Psychology), Self, Social structure},
}

@article{gornicka_rozwoj_1980,
	title = {Rozwój moralny w koncepcji {Lawrence}’a {Kohlberga}},
	volume = {6},
	journal = {Człowiek i Światopogląd},
	author = {Górnicka, J},
	year = {1980},
	pages = {113--123},
}

@book{greene_moral_2013,
	address = {London},
	title = {Moral {Tribes}: {Emotion}, {Reason}, and the {Gap} {Between} {Us} and {Them}},
	isbn = {978-1-78239-336-8},
	shorttitle = {Moral {Tribes}},
	abstract = {A neuroscientist explores how globalization has illuminated the deep moral divisions between opposing sides, drawing on pioneering research to reveal the evolutionary sources of morality while outlining recommendations for bridging divided cultures},
	language = {en},
	publisher = {Atlantic Books},
	author = {Greene, Joshua David},
	year = {2013},
	note = {OCLC: 870416027},
	keywords = {Conditions morales, Emotions Moral and ethical aspects, Group identity Moral and ethical aspects, History, Identité collective Aspect moral, Instinct Aspect moral, Instinct Moral and ethical aspects, Moral conditions, Neuropsychology Moral and ethical aspects, Raison Aspect moral, Reason Moral and ethical aspects, Tribes Moral and ethical aspects History, Tribus Aspect moral Histoire, utilitarianism, Utilitarianism, Utilitarisme},
}

@article{harsanyi_can_1975,
	title = {Can the {Maximin} {Principle} {Serve} as a {Basis} for {Morality}? {A} {Critique} of {John} {Rawls}'s {Theory}},
	volume = {69},
	issn = {0003-0554},
	shorttitle = {Can the {Maximin} {Principle} {Serve} as a {Basis} for {Morality}?},
	url = {https://www.jstor.org/stable/1959090},
	doi = {10.2307/1959090},
	language = {en},
	number = {2},
	urldate = {2023-01-11},
	journal = {The American Political Science Review},
	author = {Harsanyi, John C.},
	editor = {Rawls, John},
	year = {1975},
	note = {Publisher: [American Political Science Association, Cambridge University Press]},
	pages = {594--606},
	file = {JSTOR Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/VN6DM4YU/Harsanyi - 1975 - Can the Maximin Principle Serve as a Basis for Mor.pdf:application/pdf},
}

@book{hofstede_cultures_2010,
	address = {New York},
	edition = {3rd ed},
	title = {Cultures and {Organizations}: {Software} of the {Mind}: {Intercultural} {Cooperation} and {Its} {Importance} for {Survival}},
	isbn = {978-0-07-177015-6},
	shorttitle = {Cultures and {Organizations}},
	language = {en},
	publisher = {McGraw-Hill},
	author = {Hofstede, Geert H. and Hofstede, Gert Jan and Minkov, Michael},
	year = {2010},
	keywords = {Research, Organization, Ethnopsychology, Cultural pluralism, Intercultural communication, International cooperation, National characteristics},
	file = {Hofstede et al. - 2010 - Cultures and organizations software of the mind .pdf:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/LTVT4AVE/Hofstede et al. - 2010 - Cultures and organizations software of the mind .pdf:application/pdf},
}

@book{hofstede_kultury_2007,
	address = {Warszawa},
	edition = {Wyd. 2 zm},
	title = {Kultury i organizacje: zaprogramowanie umysłu},
	isbn = {978-83-208-1685-3},
	shorttitle = {Kultury i organizacje},
	language = {pol},
	publisher = {Polskie Wydawnictwo Ekonomiczne},
	author = {Hofstede, Geert and Hofstede, Gert Jan and Durska, Małgorzata},
	year = {2007},
	keywords = {Etnopsychologia, Komunikacja międzykulturowa, Pluralizm kulturowy, Współpraca międzynarodowa, Zachowania w organizacji},
	annote = {Aut. wyd. 1: Geert Hofstede},
}

@inproceedings{holstein_avoiding_2018,
	address = {Gothenburg Sweden},
	title = {Avoiding the intrinsic unfairness of the trolley problem},
	isbn = {978-1-4503-5746-3},
	url = {https://dl.acm.org/doi/10.1145/3194770.3194772},
	doi = {10.1145/3194770.3194772},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Proceedings of the {International} {Workshop} on {Software} {Fairness}},
	publisher = {ACM},
	author = {Holstein, Tobias and Dodig-Crnkovic, Gordana},
	month = may,
	year = {2018},
	pages = {32--37},
	file = {Pełny tekst:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/ME7ZCL8Z/Holstein i Dodig-Crnkovic - 2018 - Avoiding the intrinsic unfairness of the trolley p.pdf:application/pdf},
}

@book{inglehart_modernization_2005,
	address = {Cambridge},
	title = {Modernization, {Cultural} {Change}, and {Democracy}: {The} {Human} {Development} {Sequence}},
	isbn = {978-0-521-84695-0},
	shorttitle = {Modernization, {Cultural} {Change}, and {Democracy}},
	url = {https://www.cambridge.org/core/books/modernization-cultural-change-and-democracy/4321210B04C63808615846DB0E3EEC34},
	abstract = {This book demonstrates that people's basic values and beliefs are changing, in ways that affect their political, sexual, economic, and religious behaviour. These changes are roughly predictable: to a large extent, they can be interpreted on the basis of a revised version of modernisation theory presented here. Drawing on a massive body of evidence from societies containing 85 percent of the world's population, the authors demonstrate that modernisation is a process of human development, in which economic development gives rise to cultural changes that make individual autonomy, gender equality, and democracy increasingly likely. The authors present a model of social change that predicts how the value systems play a crucial role in the emergence and flourishing of democratic institutions - and that modernisation brings coherent cultural changes that are conducive to democratisation.},
	language = {en},
	urldate = {2023-01-11},
	publisher = {Cambridge University Press},
	author = {Inglehart, Ronald and Welzel, Christian},
	year = {2005},
	doi = {10.1017/CBO9780511790881},
	file = {Snapshot:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/QUMFRPXI/4321210B04C63808615846DB0E3EEC34.html:text/html},
}

@article{jorgensen_imperatives_1937,
	title = {Imperatives and logic},
	volume = {7},
	issn = {1572-8420},
	url = {https://doi.org/10.1007/BF00666538},
	doi = {10.1007/BF00666538},
	language = {en},
	number = {1},
	urldate = {2023-01-11},
	journal = {Erkenntnis},
	author = {Jörgensen, Jörgen},
	month = jan,
	year = {1937},
	pages = {288--296},
	file = {Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/H7UGC397/Jörgensen - 1937 - Imperatives and logic.pdf:application/pdf},
}

@article{karpus_algorithm_2021,
	title = {Algorithm exploitation: {Humans} are keen to exploit benevolent {AI}},
	volume = {24},
	issn = {2589-0042},
	shorttitle = {Algorithm exploitation},
	url = {https://www.sciencedirect.com/science/article/pii/S2589004221006477},
	doi = {10.1016/j.isci.2021.102679},
	abstract = {We cooperate with other people despite the risk of being exploited or hurt. If future artificial intelligence (AI) systems are benevolent and cooperative toward us, what will we do in return? Here we show that our cooperative dispositions are weaker when we interact with AI. In nine experiments, humans interacted with either another human or an AI agent in four classic social dilemma economic games and a newly designed game of Reciprocity that we introduce here. Contrary to the hypothesis that people mistrust algorithms, participants trusted their AI partners to be as cooperative as humans. However, they did not return AI's benevolence as much and exploited the AI more than humans. These findings warn that future self-driving cars or co-working robots, whose success depends on humans' returning their cooperativeness, run the risk of being exploited. This vulnerability calls not just for smarter machines but also better human-centered policies.},
	language = {en},
	number = {6},
	urldate = {2023-01-11},
	journal = {iScience},
	author = {Karpus, Jurgis and Krüger, Adrian and Verba, Julia Tovar and Bahrami, Bahador and Deroy, Ophelia},
	month = jun,
	year = {2021},
	keywords = {Computer science, Social sciences, Sociology},
	pages = {102679},
	file = {ScienceDirect Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/GZ5WPWCV/Karpus et al. - 2021 - Algorithm exploitation Humans are keen to exploit.pdf:application/pdf;ScienceDirect Snapshot:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/YRARLQV6/S2589004221006477.html:text/html},
}

@phdthesis{kohlberg_development_1958,
	address = {Chicago, IL},
	type = {{PhD} thesis},
	title = {The {Development} of {Modes} of {Moral} {Thinking} and {Choice} in the {Years} 10 to 16},
	url = {https://www.proquest.com/openview/c503bf59d762abe5818e1b24c484d41a/1?pq-origsite=gscholar&cbl=18750&diss=y},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
	language = {en},
	urldate = {2023-01-11},
	school = {University of Chicago},
	author = {Kohlberg, Lawrence},
	year = {1958},
	file = {Kohlberg - 1958 - The Development of Modes of Moral Thinking and Cho.pdf:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/EISEJZEM/Kohlberg - 1958 - The Development of Modes of Moral Thinking and Cho.pdf:application/pdf;Snapshot:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/EYWTAXUJ/1.html:text/html},
}

@article{maroto-gomez_adaptive_2022,
	title = {An adaptive decision-making system supported on user preference predictions for human–robot interactive communication},
	issn = {0924-1868, 1573-1391},
	url = {https://link.springer.com/10.1007/s11257-022-09321-2},
	doi = {10.1007/s11257-022-09321-2},
	abstract = {Abstract
            Adapting to dynamic environments is essential for artificial agents, especially those aiming to communicate with people interactively. In this context, a social robot that adapts its behaviour to different users and proactively suggests their favourite activities may produce a more successful interaction. In this work, we describe how the autonomous decision-making system embedded in our social robot Mini can produce a personalised interactive communication experience by considering the preferences of the user the robot interacts with. We compared the performance of Top Label as Class and Ranking by Pairwise Comparison, two promising algorithms in the area, to find the one that best predicts the user preferences. Although both algorithms provide robust results in preference prediction, we decided to integrate Ranking by Pairwise Comparison since it provides better estimations. The method proposed in this contribution allows the autonomous decision-making system of the robot to work on different modes, balancing activity exploration with the selection of the favourite entertaining activities. The operation of the preference learning system is shown in three real case studies where the decision-making system works differently depending on the user the robot is facing. Then, we conducted a human–robot interaction experiment to investigate whether the robot users perceive the personalised selection of activities more appropriate than selecting the activities at random. The results show how the study participants found the personalised activity selection more appropriate, improving their likeability towards the robot and how intelligent they perceive the system. query Please check the edit made in the article title.},
	language = {en},
	urldate = {2023-01-11},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Maroto-Gómez, Marcos and Castro-González, Álvaro and Castillo, José Carlos and Malfaz, María and Salichs, Miguel Ángel},
	month = apr,
	year = {2022},
	pages = {1--45},
	file = {Pełny tekst:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/B2JL6PR3/Maroto-Gómez et al. - 2022 - An adaptive decision-making system supported on us.pdf:application/pdf},
}

@article{milaszewicz_zaufanie_2016,
	title = {Zaufanie jako wartość społeczna},
	issn = {2083-8611},
	url = {http://cejsh.icm.edu.pl/cejsh/element/bwmeta1.element.cejsh-d64b921a-5db7-4208-9eb7-73baaa05f7e4},
	language = {PL},
	number = {259},
	urldate = {2023-01-11},
	journal = {Studia Ekonomiczne},
	author = {Miłaszewicz, Danuta},
	year = {2016},
	note = {Publisher: Wydawnictwo Uniwersytetu Ekonomicznego w Katowicach},
	pages = {80--88},
	file = {Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/VP35FCKJ/Miłaszewicz - 2016 - Zaufanie jako wartość społeczna.pdf:application/pdf},
}

@inproceedings{mirnig_trolled_2019,
	address = {Glasgow Scotland Uk},
	title = {Trolled by the {Trolley} {Problem}: {On} {What} {Matters} for {Ethical} {Decision} {Making} in {Automated} {Vehicles}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Trolled by the {Trolley} {Problem}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300739},
	doi = {10.1145/3290605.3300739},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Mirnig, Alexander G. and Meschtscherjakov, Alexander},
	month = may,
	year = {2019},
	pages = {1--10},
}

@article{mittelstadt_ethics_2016,
	title = {The ethics of algorithms: {Mapping} the debate},
	volume = {3},
	issn = {2053-9517, 2053-9517},
	shorttitle = {The ethics of algorithms},
	url = {http://journals.sagepub.com/doi/10.1177/2053951716679679},
	doi = {10.1177/2053951716679679},
	abstract = {In information societies, operations, decisions and choices previously left to humans are increasingly delegated to algorithms, which may advise, if not decide, about how data should be interpreted and what actions should be taken as a result. More and more often, algorithms mediate social processes, business transactions, governmental decisions, and how we perceive, understand, and interact among ourselves and with the environment. Gaps between the design and operation of algorithms and our understanding of their ethical implications can have severe consequences affecting individuals as well as groups and whole societies. This paper makes three contributions to clarify the ethical importance of algorithmic mediation. It provides a prescriptive map to organise the debate. It reviews the current discussion of ethical aspects of algorithms. And it assesses the available literature in order to identify areas requiring further work to develop the ethics of algorithms.},
	language = {en},
	number = {2},
	urldate = {2023-01-11},
	journal = {Big Data \& Society},
	author = {Mittelstadt, Brent Daniel and Allo, Patrick and Taddeo, Mariarosaria and Wachter, Sandra and Floridi, Luciano},
	month = dec,
	year = {2016},
	pages = {1--21},
	file = {Pełny tekst:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/TDCM7BIE/Mittelstadt et al. - 2016 - The ethics of algorithms Mapping the debate.pdf:application/pdf},
}

@book{nagel_view_1986,
	address = {Oxford},
	edition = {1},
	title = {The {View} from {Nowhere}},
	isbn = {978-0-19-505644-0},
	language = {eng},
	publisher = {Oxford University Press},
	author = {Nagel, Thomas},
	year = {1986},
	annote = {Literaturverzeichnis: Seite 233-238},
	file = {Table of Contents PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/TZ79NT2N/Nagel - 1989 - The view from nowhere.pdf:application/pdf},
}

@book{nozick_anarchy_2013,
	address = {New York},
	title = {Anarchy, {State}, and {Utopia}},
	isbn = {978-0-465-05100-7},
	language = {en},
	publisher = {Basic Books},
	author = {Nozick, Robert},
	year = {2013},
	keywords = {State, The, Anarchism, Civil rights, Human rights, Utopias},
}

@book{pasquale_black_2016,
	address = {Cambridge, MA},
	title = {The {Black} {Box} {Society}: {The} {Secret} {Algorithms} {That} {Control} {Money} and {Information}},
	isbn = {978-0-674-97084-7},
	shorttitle = {The {Black} {Box} {Society}},
	abstract = {On WNYC’s Brian Lehrer Show, listen to Frank Pasquale discuss why we need much stricter regulation of how personal data is stored and used:
	

Every day, corporations are connecting the dots about our personal behavior—silently scrutinizing clues left behind by our work habits and Internet use. The data compiled and portraits created are incredibly detailed, to the point of being invasive. But who connects the dots about what firms are doing with this information? The Black Box Society argues that we all need to be able to do so—and to set limits on how big data affects our lives.
Hidden algorithms can make (or ruin) reputations, decide the destiny of entrepreneurs, or even devastate an entire economy. Shrouded in secrecy and complexity, decisions at major Silicon Valley and Wall Street firms were long assumed to be neutral and technical. But leaks, whistleblowers, and legal disputes have shed new light on automated judgment. Self-serving and reckless behavior is surprisingly common, and easy to hide in code protected by legal and real secrecy. Even after billions of dollars of fines have been levied, underfunded regulators may have only scratched the surface of this troubling behavior.
Frank Pasquale exposes how powerful interests abuse secrecy for profit and explains ways to rein them in. Demanding transparency is only the first step. An intelligible society would assure that key decisions of its most important firms are fair, nondiscriminatory, and open to criticism. Silicon Valley and Wall Street need to accept as much accountability as they impose on others.},
	language = {en},
	publisher = {Harvard University Press},
	author = {Pasquale, Frank},
	month = aug,
	year = {2016},
	file = {Snapshot:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/CE3JDH8I/catalog.html:text/html},
}

@book{rawls_theory_1971,
	address = {Cambridge, MA},
	title = {A {Theory} of {Justice}},
	isbn = {978-0-674-88014-6},
	url = {http://www.gbv.de/dms/bowker/toc/9780674880146.pdf},
	abstract = {This volume is a widely-read book of political philosophy and ethics. Arguing for a principled reconciliation of liberty and equality, it attempts to solve the problem of distributive justice (this concerns what is considered to be socially just with respect to the allocation of goods in a society). The resultant theory is known as "Justice as Fairness", from which the author derives his two famous principles of justice. The first of these two principles is known as the equal liberty principle. The second principle is split into two parts; the first, known as fair equality of opportunity, asserts that justice should not benefit those with advantageous social contingencies; while the second, reflecting the idea that inequality is only justified if it is to the advantage of those who are less well-off, is known as the difference principle},
	language = {en},
	urldate = {2023-01-11},
	publisher = {The Belknap Press of Harvard University Press},
	author = {Rawls, John},
	year = {1971},
	keywords = {Festschriften, Justice, Justice (Philosophy), Justice sociale, Philosophie, philosophy, Philosophy, Rechtvaardigheid, Social justice, Social Justice},
}

@book{rosenbloom_computing_2013,
	address = {Cambridge, MA},
	title = {On {Computing}: {The} {Fourth} {Great} {Scientific} {Domain}},
	isbn = {978-0-262-52828-3 978-0-262-01832-6},
	shorttitle = {On {Computing}},
	language = {en},
	publisher = {MIT Press},
	author = {Rosenbloom, Paul S.},
	year = {2013},
	annote = {Includes bibliographical references (p. [255]-287) and index},
	file = {Table of Contents PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/SWN6RILV/Rosenbloom - 2013 - On computing the fourth great scientific domain.pdf:application/pdf},
}

@article{searle_how_1964,
	title = {How to {Derive} "{Ought}" {From} "{Is}"},
	volume = {73},
	issn = {0031-8108},
	url = {https://www.jstor.org/stable/2183201},
	doi = {10.2307/2183201},
	language = {en},
	number = {1},
	urldate = {2023-01-11},
	journal = {The Philosophical Review},
	author = {Searle, John R.},
	year = {1964},
	note = {Publisher: [Duke University Press, Philosophical Review]},
	pages = {43--58},
	file = {JSTOR Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/A4V3GZEN/Searle - 1964 - How to Derive Ought From Is.pdf:application/pdf},
}

@article{shariff_psychological_2017,
	title = {Psychological roadblocks to the adoption of self-driving vehicles},
	volume = {1},
	copyright = {2017 The Publisher},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-017-0202-6},
	doi = {10.1038/s41562-017-0202-6},
	abstract = {Self-driving cars offer a bright future, but only if the public can overcome the psychological challenges that stand in the way of widespread adoption. We discuss three: ethical dilemmas, overreactions to accidents, and the opacity of the cars’ decision-making algorithms — and propose steps towards addressing them.},
	language = {en},
	number = {10},
	urldate = {2023-01-11},
	journal = {Nature Human Behaviour},
	author = {Shariff, Azim and Bonnefon, Jean-François and Rahwan, Iyad},
	month = oct,
	year = {2017},
	note = {Number: 10
Publisher: Nature Publishing Group},
	keywords = {Ethics, Human behaviour},
	pages = {694--696},
	file = {Zaakceptowana wersja:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/GYQRRC47/Shariff et al. - 2017 - Psychological roadblocks to the adoption of self-d.pdf:application/pdf},
}

@article{splawska_poziom_2008,
	title = {Poziom rozwoju rozumowania moralnego w świetle badań metodą {Lawrence}’a {Kolberga}},
	issn = {1897-6557},
	url = {http://cejsh.icm.edu.pl/cejsh/element/bwmeta1.element.desklight-c8ca79ea-352b-4b0f-b9da-8ee9986895b8},
	language = {pl},
	number = {2},
	urldate = {2023-01-11},
	journal = {Przegląd Pedagogiczny},
	author = {Spławska, Joanna},
	year = {2008},
	note = {Publisher: Wydawnictwo Uniwersytetu Kazimierza Wielkiego w Bydgoszczy},
	pages = {107--120},
	file = {Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/YB6NY727/Spławska - 2008 - Poziom rozwoju rozumowania moralnego w świetle bad.pdf:application/pdf},
}

@article{stacewicz_computer_2019,
	title = {From {Computer} {Science} to the {Informational} {Worldview}. {Philosophical} {Interpretations} of {Some} {Computer} {Science} {Concepts}},
	volume = {44},
	url = {https://sciendo.com/pl/article/10.2478/fcds-2019-0003},
	doi = {10.2478/fcds-2019-0003},
	abstract = {AbstractIn this article I defend the thesis that modern computer science has a significant philosophical potential, which is expressed in a form of worldview, called here informational worldview (IVW). It includes such theses like: a) each being contains a certain informational content (which may be revealed by computer science concepts, such as code or algorithm), b) the mind is an information processing system (which should be modeled by means of data processing systems), c) cognition is a type of computation. These (pre)philosophical theses are accepted in many sciences (e.g. in cognitive science), and this is both an expression and strengthening of the IWV. After a general discussion of the relations between philosophy, particular sciences and the worldview, and then the presentation of the basic assumptions and theses of the IWV, I analyze a certain specification of thesis b) expressed in the statement that “the mind is the Turing machine”. I distinguish three concepts of mind (static, variable and minimal) and explain how each of them is connected with the concept of the Turing machine.},
	language = {en},
	number = {1},
	urldate = {2023-01-11},
	journal = {Foundations of Computing and Decision Sciences},
	author = {Stacewicz, Paweł},
	month = mar,
	year = {2019},
	pages = {27--43},
	file = {Full Text PDF:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/XCWVWUU4/Stacewicz - 2019 - From Computer Science to the Informational Worldvi.pdf:application/pdf},
}

@article{szymanska_conjoint_2005,
	title = {Conjoint analysis jako metoda analizy preferencji konsumentów},
	issn = {0208-7944},
	url = {http://bazekon.icm.edu.pl/bazekon/element/bwmeta1.element.ekon-element-000105096494},
	language = {PL},
	number = {680},
	urldate = {2023-01-11},
	journal = {Zeszyty Naukowe Akademii Ekonomicznej w Krakowie},
	author = {Szymańska, Anna and Dziedzic, Dorota},
	year = {2005},
	pages = {153--165},
	file = {Snapshot:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/VK5GDS96/bwmeta1.element.html:text/html},
}

@book{yudkowsky_coherent_2004,
	address = {San Francisco, CA},
	title = {Coherent {Extrapolated} {Volition}},
	language = {en},
	publisher = {San Francisco},
	author = {Yudkowsky, Eliezer},
	year = {2004},
	file = {Yudkowsky - Coherent Extrapolated Volition.pdf:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/RJDSXAY7/Yudkowsky - Coherent Extrapolated Volition.pdf:application/pdf},
}

@misc{peruzzi_beginners_2015,
	title = {A {Beginner}'s {Guide} to {Conjoint} {Analysis}},
	url = {https://www.youtube.com/watch?v=RvmZG4cFU0k},
	language = {en},
	urldate = {2023-01-11},
	journal = {QuestionPro},
	author = {Peruzzi, Nico and Aseron, Rob and Bhaskaran, Vivek},
	month = may,
	year = {2015},
}

@misc{dignum_responsible_2022,
	title = {Responsible {AI}: {From} {Principles} to {Action}},
	shorttitle = {Virginia {Dignum}, {Responsible} {AI}},
	url = {https://www.youtube.com/watch?v=LwKDOwwJpL4},
	urldate = {2023-01-11},
	journal = {Michigan Institute for Data Science},
	author = {Dignum, Virginia},
	month = mar,
	year = {2022},
}

@misc{gryz_sztuczna_2021,
	title = {Sztuczna {Inteligencja}: powstanie, rozwój, rokowania},
	shorttitle = {Sztuczna {Inteligencja}},
	url = {https://www.youtube.com/watch?v=3ZDfVgC897k},
	language = {pl},
	urldate = {2023-01-11},
	journal = {Copernicus Center},
	author = {Gryz, Jarek},
	month = apr,
	year = {2021},
}

@misc{edmonds_americans_2017,
	title = {Americans {Feel} {Unsafe} {Sharing} the {Road} with {Fully} {Self}-{Driving} {Cars}},
	url = {https://newsroom.aaa.com/2017/03/americans-feel-unsafe-sharing-road-fully-self-driving-cars/},
	abstract = {New AAA survey reveals that Americans still leery of a driverless future},
	language = {en-US},
	urldate = {2023-01-11},
	journal = {AAA Newsroom},
	author = {Edmonds, Ellen},
	month = mar,
	year = {2017},
	file = {Snapshot:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/APHWR479/americans-feel-unsafe-sharing-road-fully-self-driving-cars.html:text/html},
}

@misc{szreder_rozne_2021,
	title = {Różne oblicza istotności statystycznej},
	url = {https://www.youtube.com/watch?v=QsJLCxHY794},
	language = {pl},
	urldate = {2023-01-11},
	journal = {Copernicus Center},
	author = {Szreder, Mirosław},
	month = jun,
	year = {2021},
}

@misc{hofstede_geert_2011,
	title = {Geert {Hofstede} on {Culture}},
	url = {https://www.youtube.com/watch?v=wdh40kgyYOY},
	urldate = {2023-01-11},
	journal = {Viewdutch},
	author = {Hofstede, Gert Jan},
	month = oct,
	year = {2011},
}

@misc{noauthor_sztuczna_2019,
	title = {Sztuczna inteligencja zachęcała do samobójstwa},
	url = {https://wgospodarce.pl/informacje/73035-sztuczna-inteligencja-zachecala-do-samobojstwa},
	abstract = {Asystentka Alexa z Amazon Echo namawiała do „dźgnięcia się w serce dla większego dobra”},
	language = {pl},
	urldate = {2023-01-11},
	month = dec,
	year = {2019},
	file = {Snapshot:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/ZB4CBVQ2/73035-sztuczna-inteligencja-zachecala-do-samobojstwa.html:text/html},
}

@misc{lo_my_2019,
	title = {"{My} {Amazon} {Alexa} {Went} {Rogue} and {Ordered} {Me} to {Stab} {Myself} in the {Heart}"},
	url = {https://www.mirror.co.uk/news/uk-news/my-amazon-echo-went-rogue-21127994},
	urldate = {2023-01-11},
	journal = {Mirror Online},
	author = {Lo, Tiffany},
	month = dec,
	year = {2019},
	file = {"My Amazon Alexa went rogue and ordered me to stab myself in the heart" - Mirror Online:/home/pawel/.zotero/zotero/2felkxqq.default/zotero/storage/5IPBYEX4/my-amazon-echo-went-rogue-21127994.html:text/html},
}
